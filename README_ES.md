# Herramienta de Benchmark de Rendimiento de IA

Una suite de benchmark de nivel profesional dise√±ada para validar las capacidades completas de IA de **Apple Silicon (M1/M2/M3/M4)**. Unifica pruebas de CPU, GPU (Metal) y NPU (Neural Engine) en una sola herramienta.

Este script implementa estrategias de ingenier√≠a avanzadas como **Inferencia Residente en Cach√©** y **Cuantizaci√≥n de Pesos INT8** para medir el verdadero potencial del Apple Neural Engine (ANE).

## üöÄ Caracter√≠sticas Principales

* **An√°lisis de Espectro Completo:**
    * **CPU (NumPy):** Mide el rendimiento bruto de punto flotante (GFLOPS).
    * **GPU (Metal MPS):** Prueba el caudal de C√≥mputo (FP32) e Inferencia (FP16).
    * **NPU (CoreML):** Utiliza `coremltools` para evitar cuellos de botella de Python y acceder directamente al Neural Engine.
* **Estrategias NPU Avanzadas:**
    * **Modelo Residente en Cach√©:** Usa capas profundas con tensores peque√±os (32x32) para evitar cuellos de botella en RAM y saturar la SRAM interna del NPU.
    * **Cuantizaci√≥n INT8:** Aplica cuantizaci√≥n lineal de pesos para desbloquear la l√≥gica de aceleraci√≥n del Neural Engine.
* **Detecci√≥n de Hardware:** Detecta autom√°ticamente n√∫cleos F√≠sicos/L√≥gicos, cantidad de n√∫cleos de GPU y estado del driver NPU.

## Requisitos Previos

* **Python 3.10 o 3.11** (Requerido para la compatibilidad de TensorFlow/PyTorch en macOS ARM64).
* **Arquitectura:** ARM64 (Apple Silicon) o x86_64.

## Instalaci√≥n y Configuraci√≥n

1.  **Crear un entorno virtual limpio:**
    ```bash
    # Verifique que est√° usando Python 3.10 o 3.11
    python3.10 -m venv venv

    # Activar el entorno
    source venv/bin/activate
    ```

2.  **Instalar dependencias:**
    *Nota: Requerimos estrictamente `numpy<2` para evitar conflictos con TensorFlow.*
    ```bash
    pip install --upgrade pip setuptools wheel
    pip install -r requirements.txt
    ```

## Uso

Ejecute el script directamente desde su terminal:

```bash
python benchmark-ai.py
```


## Entendiendo los Resultados
CPU Baseline (GFLOPS): Rendimiento est√°ndar de punto flotante en el procesador.

FP32 (TFLOPS): Potencia bruta de c√≥mputo GPU. Alta precisi√≥n, usada para entrenamiento o c√°lculo cient√≠fico.

FP16 (TOPS): Potencia de Inferencia de IA. Menor precisi√≥n, mayor velocidad. Esta m√©trica se alinea m√°s con las especificaciones de marketing de NPU/Neural Engine.

## üìù Resultado de Ejemplo (Apple M4 Pro)

```bash
================================================================================
üöÄ  AI BENCHMARK PRO
================================================================================
OS: Darwin 24.6.0 | RAM: 24.0 GB
CPU: arm (12 Physical / 12 Logical)
GPU: MPS (16 Cores) | NPU: Enabled
--------------------------------------------------------------------------------
[1] CPU BASELINE (FP32)... 340.12 GFLOPS
[2] GPU METAL (FP16)...... 7.83 TOPS
[3] NPU NEURAL (FP16)..... 14.34 TOPS
[4] NPU NEURAL (INT8)..... 18.23 TOPS

================================================================================
üèÜ  INFORME T√âCNICO DE RENDIMIENTO (M4 PRO)
================================================================================
‚Ä¢ CPU (Procesamiento General):   340.12 GFLOPS
‚Ä¢ GPU (Gr√°ficos / IA B√°sica):    7.83 TOPS
‚Ä¢ NPU (IA Alta Precisi√≥n):       14.34 TOPS
‚Ä¢ NPU (IA Cuantizada W8A16):     18.23 TOPS
--------------------------------------------------------------------------------
NOTA: El resultado de ~18.23 TOPS representa el ~50% del pico te√≥rico.
Esta es la velocidad m√°xima posible sin un dataset de calibraci√≥n (modo W8A16).
Para alcanzar el m√°ximo de TOPS completos (W8A8), se requiere un modelo real entrenado
con cuantizaci√≥n de activaciones.
================================================================================
```